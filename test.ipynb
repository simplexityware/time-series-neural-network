{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n"
     ]
    }
   ],
   "source": [
    "import pytorch_lightning as pl\n",
    "pl.seed_everything(42)\n",
    "import torch\n",
    "from neuralforecast.data.tsdataset import WindowsDataset\n",
    "from neuralforecast.data.tsloader import TimeSeriesLoader\n",
    "from neuralforecast.experiments.utils import get_mask_dfs\n",
    "from neuralforecast.data.utils import create_synthetic_tsdata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_df, X_df, S_df = create_synthetic_tsdata(sort=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>unique_id</th>\n",
       "      <th>ds</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>uid_1</td>\n",
       "      <td>2020-12-31</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>uid_10</td>\n",
       "      <td>2020-12-22</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>uid_10</td>\n",
       "      <td>2020-12-23</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>uid_10</td>\n",
       "      <td>2020-12-24</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>uid_10</td>\n",
       "      <td>2020-12-25</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  unique_id         ds  y\n",
       "0     uid_1 2020-12-31  1\n",
       "0    uid_10 2020-12-22  1\n",
       "1    uid_10 2020-12-23  2\n",
       "2    uid_10 2020-12-24  3\n",
       "3    uid_10 2020-12-25  4"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2080, 4)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(64, 2)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "S_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_length = 5\n",
    "encoder_length = 10\n",
    "batch_size = 16  # set this to a value which your GPU can handle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = WindowsDataset(Y_df=Y_df, X_df=X_df, S_df=S_df, \n",
    "                            #    mask_df=train_mask_df, f_cols=feat_config.time_varying_known_categoricals + feat_config.time_varying_known_reals,\n",
    "                               input_size=encoder_length,\n",
    "                               output_size=prediction_length,\n",
    "                               # sample_freq=1,\n",
    "                               # complete_windows=False,\n",
    "                               verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = TimeSeriesLoader(dataset=train_dataset,\n",
    "                                batch_size=batch_size,\n",
    "                                # n_windows=1024,\n",
    "                                eq_batch_size=True,\n",
    "                                shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "sizes of x =\n",
      "\tS = torch.Size([16, 1])\n",
      "\tY = torch.Size([16, 15])\n",
      "\tX = torch.Size([16, 2, 15])\n",
      "\tavailable_mask = torch.Size([16, 15])\n",
      "\tsample_mask = torch.Size([16, 15])\n",
      "\tidxs = torch.Size([16])\n"
     ]
    }
   ],
   "source": [
    "batch = next(iter(train_dataloader))\n",
    "print(\"\\nsizes of x =\")\n",
    "for key, value in batch.items():\n",
    "    print(f\"\\t{key} = {value.size()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "from neuralforecast.models.transformer.autoformer import Autoformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from neuralforecast.data.datasets.long_horizon import LongHorizon\n",
    "\n",
    "# Y_df, X_df, S_df = LongHorizon.load(directory='./data', group='ETTm2')\n",
    "# Y_df = Y_df.reset_index(drop=True)\n",
    "# Y_df.loc[Y_df['unique_id']=='OT','y'] = Y_df[Y_df['unique_id']=='OT']['y'] + 100 #To obseve differences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# f_cols = X_df.drop(columns=['unique_id', 'ds']).columns.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "mc_model = {}\n",
    "\n",
    "mc_model['seq_len'] = encoder_length\n",
    "mc_model['label_len'] = encoder_length//2\n",
    "mc_model['pred_len'] = prediction_length\n",
    "mc_model['output_attention'] = False\n",
    "mc_model['enc_in'] = 4\n",
    "mc_model['dec_in'] = 4\n",
    "mc_model['d_model'] = 512\n",
    "mc_model['c_out'] = 7\n",
    "mc_model['embed'] = 'timeF'\n",
    "mc_model['freq'] = 'h'\n",
    "mc_model['dropout'] = 0.05\n",
    "mc_model['factor'] = 1\n",
    "mc_model['n_heads'] = 8\n",
    "mc_model['d_ff'] = 2_048\n",
    "mc_model['moving_avg'] = 25 \n",
    "mc_model['activation'] = 'gelu'\n",
    "mc_model['e_layers'] = 2 \n",
    "mc_model['d_layers'] = 1\n",
    "mc_model['loss_train'] = 'MAE'\n",
    "mc_model['loss_hypar'] = 0.5\n",
    "mc_model['loss_valid'] = 'MAE'\n",
    "mc_model['learning_rate'] = 0.001\n",
    "mc_model['lr_decay'] = 0.5\n",
    "mc_model['weight_decay'] = 0.\n",
    "mc_model['lr_decay_step_size'] = 2\n",
    "mc_model['random_seed'] = 1\n",
    "\n",
    "# # Dataset parameters\n",
    "# mc_data = {}\n",
    "# mc_data['mode'] = 'iterate_windows'\n",
    "# mc_data['n_time_in'] = mc_model['seq_len']\n",
    "# mc_data['n_time_out'] = mc_model['pred_len']\n",
    "# mc_data['batch_size'] = 2\n",
    "# mc_data['scaler'] = None\n",
    "# mc_data['max_epochs'] = None\n",
    "# mc_data['max_steps'] = 1\n",
    "# mc_data['early_stop_patience'] = 20\n",
    "# mc_data['normalizer_y'] = None\n",
    "# mc_data['normalizer_x'] = None\n",
    "\n",
    "len_val = 11_520\n",
    "len_test = 11_520"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from neuralforecast.data.tsdataset import IterateWindowsDataset\n",
    "# from neuralforecast.experiments.utils import create_datasets\n",
    "# from torch.utils.data import DataLoader\n",
    "\n",
    "\n",
    "# train_dataset, val_dataset, test_dataset = create_datasets(mc=mc_data,\n",
    "#                                                                      S_df=None, \n",
    "#                                                                      Y_df=Y_df, X_df=X_df,\n",
    "#                                                                      f_cols=f_cols,\n",
    "#                                                                      ds_in_val=len_val,\n",
    "#                                                                      ds_in_test=len_test)\n",
    "\n",
    "# train_loader = DataLoader(dataset=train_dataset,\n",
    "#                           batch_size=int(mc_data['batch_size']),\n",
    "#                           shuffle=True,\n",
    "#                           drop_last=True)\n",
    "\n",
    "# val_loader = DataLoader(dataset=val_dataset,\n",
    "#                         batch_size=int(mc_data['batch_size']),\n",
    "#                         shuffle=False)\n",
    "\n",
    "# test_loader = DataLoader(dataset=test_dataset,\n",
    "#                          batch_size=int(mc_data['batch_size']),\n",
    "#                          shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# batch = next(iter(train_dataloader))\n",
    "# print(\"\\nsizes of x =\")\n",
    "# for key, value in batch.items():\n",
    "#     print(f\"\\t{key} = {value.size()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Autoformer(\n",
    "    **mc_model\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.to(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in batch.keys():\n",
    "    batch[key] = batch[key].to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Given groups=1, weight of size [512, 4, 3], expected input[1, 16, 12] to have 4 channels, but got 16 channels instead",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\ManuJoseph\\OneDrive - Thoucentric\\Work\\Projects\\Playground\\AdvancedTimeSeriesForecastingBook\\Github\\Modern-Time-Series-Forecasting-with-Python-\\test.ipynb Cell 19\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/ManuJoseph/OneDrive%20-%20Thoucentric/Work/Projects/Playground/AdvancedTimeSeriesForecastingBook/Github/Modern-Time-Series-Forecasting-with-Python-/test.ipynb#X12sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m model(batch)\n",
      "File \u001b[1;32mc:\\Users\\ManuJoseph\\miniconda3\\envs\\modern_ts_v3\\lib\\site-packages\\torch\\nn\\modules\\module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1106\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1107\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1108\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1109\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1110\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39m\u001b[39minput\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1111\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1112\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\ManuJoseph\\miniconda3\\envs\\modern_ts_v3\\lib\\site-packages\\neuralforecast\\models\\transformer\\autoformer.py:284\u001b[0m, in \u001b[0;36mAutoformer.forward\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    282\u001b[0m     forecast \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel(batch_x, batch_x_mark, dec_inp, batch_y_mark)[\u001b[39m0\u001b[39m]\n\u001b[0;32m    283\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 284\u001b[0m     forecast \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmodel(batch_x, batch_x_mark, dec_inp, batch_y_mark)\n\u001b[0;32m    286\u001b[0m batch_y \u001b[39m=\u001b[39m batch_y[:, \u001b[39m-\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpred_len:, :]\n\u001b[0;32m    287\u001b[0m outsample_mask \u001b[39m=\u001b[39m outsample_mask[:, \u001b[39m-\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpred_len:, :]\n",
      "File \u001b[1;32mc:\\Users\\ManuJoseph\\miniconda3\\envs\\modern_ts_v3\\lib\\site-packages\\torch\\nn\\modules\\module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1106\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1107\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1108\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1109\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1110\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39m\u001b[39minput\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1111\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1112\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\ManuJoseph\\miniconda3\\envs\\modern_ts_v3\\lib\\site-packages\\neuralforecast\\models\\transformer\\autoformer.py:110\u001b[0m, in \u001b[0;36m_Autoformer.forward\u001b[1;34m(self, x_enc, x_mark_enc, x_dec, x_mark_dec, enc_self_mask, dec_self_mask, dec_enc_mask)\u001b[0m\n\u001b[0;32m    108\u001b[0m seasonal_init \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mcat([seasonal_init[:, \u001b[39m-\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlabel_len:, :], zeros], dim\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[0;32m    109\u001b[0m \u001b[39m# enc\u001b[39;00m\n\u001b[1;32m--> 110\u001b[0m enc_out \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49menc_embedding(x_enc, x_mark_enc)\n\u001b[0;32m    111\u001b[0m enc_out, attns \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mencoder(enc_out, attn_mask\u001b[39m=\u001b[39menc_self_mask)\n\u001b[0;32m    112\u001b[0m \u001b[39m# dec\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\ManuJoseph\\miniconda3\\envs\\modern_ts_v3\\lib\\site-packages\\torch\\nn\\modules\\module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1106\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1107\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1108\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1109\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1110\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39m\u001b[39minput\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1111\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1112\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\ManuJoseph\\miniconda3\\envs\\modern_ts_v3\\lib\\site-packages\\neuralforecast\\models\\components\\embed.py:138\u001b[0m, in \u001b[0;36mDataEmbedding_wo_pos.forward\u001b[1;34m(self, x, x_mark)\u001b[0m\n\u001b[0;32m    137\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, x, x_mark):\n\u001b[1;32m--> 138\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mvalue_embedding(x) \u001b[39m+\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtemporal_embedding(x_mark)\n\u001b[0;32m    139\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdropout(x)\n",
      "File \u001b[1;32mc:\\Users\\ManuJoseph\\miniconda3\\envs\\modern_ts_v3\\lib\\site-packages\\torch\\nn\\modules\\module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1106\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1107\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1108\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1109\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1110\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39m\u001b[39minput\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1111\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1112\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\ManuJoseph\\miniconda3\\envs\\modern_ts_v3\\lib\\site-packages\\neuralforecast\\models\\components\\embed.py:44\u001b[0m, in \u001b[0;36mTokenEmbedding.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     43\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, x):\n\u001b[1;32m---> 44\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtokenConv(x\u001b[39m.\u001b[39;49mpermute(\u001b[39m0\u001b[39;49m, \u001b[39m2\u001b[39;49m, \u001b[39m1\u001b[39;49m))\u001b[39m.\u001b[39mtranspose(\u001b[39m1\u001b[39m, \u001b[39m2\u001b[39m)\n\u001b[0;32m     45\u001b[0m     \u001b[39mreturn\u001b[39;00m x\n",
      "File \u001b[1;32mc:\\Users\\ManuJoseph\\miniconda3\\envs\\modern_ts_v3\\lib\\site-packages\\torch\\nn\\modules\\module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1106\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1107\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1108\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1109\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1110\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39m\u001b[39minput\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1111\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1112\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\ManuJoseph\\miniconda3\\envs\\modern_ts_v3\\lib\\site-packages\\torch\\nn\\modules\\conv.py:302\u001b[0m, in \u001b[0;36mConv1d.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    301\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[1;32m--> 302\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_conv_forward(\u001b[39minput\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias)\n",
      "File \u001b[1;32mc:\\Users\\ManuJoseph\\miniconda3\\envs\\modern_ts_v3\\lib\\site-packages\\torch\\nn\\modules\\conv.py:295\u001b[0m, in \u001b[0;36mConv1d._conv_forward\u001b[1;34m(self, input, weight, bias)\u001b[0m\n\u001b[0;32m    293\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_conv_forward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor, weight: Tensor, bias: Optional[Tensor]):\n\u001b[0;32m    294\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpadding_mode \u001b[39m!=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mzeros\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[1;32m--> 295\u001b[0m         \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mconv1d(F\u001b[39m.\u001b[39;49mpad(\u001b[39minput\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_reversed_padding_repeated_twice, mode\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpadding_mode),\n\u001b[0;32m    296\u001b[0m                         weight, bias, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mstride,\n\u001b[0;32m    297\u001b[0m                         _single(\u001b[39m0\u001b[39;49m), \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdilation, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgroups)\n\u001b[0;32m    298\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39mconv1d(\u001b[39minput\u001b[39m, weight, bias, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstride,\n\u001b[0;32m    299\u001b[0m                     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpadding, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdilation, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgroups)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Given groups=1, weight of size [512, 4, 3], expected input[1, 16, 12] to have 4 channels, but got 16 channels instead"
     ]
    }
   ],
   "source": [
    "model(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.0 ('modern_ts_v3')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "22702ba2a964f131e633b417781d12d4d347cdd58127be7481ae9e9ed5f062e1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
